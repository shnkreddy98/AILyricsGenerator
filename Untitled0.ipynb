{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc2akYwHuiWY",
        "outputId": "dfcdb44f-d688-4ce2-e90d-709811c3f48a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=667837099f172bfcf397e93906f2879f62a5a0d22a418077a316655e56ba2767\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyEw1uRyky1G",
        "outputId": "49f0298e-1089-4c60-f9f1-3f4cdbd9b9fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ],
      "source": [
        "# Install findspark to locate Spark in the system\n",
        "!pip install findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sluwk-UBuTiU"
      },
      "outputs": [],
      "source": [
        "# Import findspark and initialize Spark\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XiqbG2RZuerm"
      },
      "outputs": [],
      "source": [
        "# Import PySpark\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QT5hXRXxu2eP"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "23/11/25 15:55:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        }
      ],
      "source": [
        "# Create a Spark session\n",
        "spark = SparkSession.builder.appName(\"song_lyrics_analysis\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qwsmL8ZvCpL",
        "outputId": "362e5f1c-af26-4334-88b4-e91e539a8dd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tEYtOnAbyDbR"
      },
      "outputs": [],
      "source": [
        "file_path = 'data/song_lyrics.csv'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t93b4yAUvOuZ",
        "outputId": "6ff5031d-03bc-4246-8cec-4223191394d8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+---+---------+----+------+--------------------+--------------------+---+-------------+-----------+--------+\n",
            "|               title|tag|   artist|year| views|            features|              lyrics| id|language_cld3|language_ft|language|\n",
            "+--------------------+---+---------+----+------+--------------------+--------------------+---+-------------+-----------+--------+\n",
            "|           Killa Cam|rap|  Cam'ron|2004|173166|{\"Cam\\\\'ron\",\"Ope...|[Chorus: Opera St...|  1|           en|         en|      en|\n",
            "|          Can I Live|rap|    JAY-Z|1996|468624|                  {}|[Produced by Irv ...|  3|           en|         en|      en|\n",
            "|   Forgive Me Father|rap| Fabolous|2003|  4743|                  {}|Maybe cause I'm e...|  4|           en|         en|      en|\n",
            "|        Down and Out|rap|  Cam'ron|2004|144404|{\"Cam\\\\'ron\",\"Kan...|[Produced by Kany...|  5|           en|         en|      en|\n",
            "|              Fly In|rap|Lil Wayne|2005| 78271|                  {}|[Intro]\\nSo they ...|  6|           en|         en|      en|\n",
            "|      Lollipop Remix|rap|Lil Wayne|2008|580832|{\"Kanye West\",\"St...|[Intro: Lil Wayne...|  7|           en|         en|      en|\n",
            "|          Im Not You|rap|   Clipse|2002| 28645|{Jadakiss,\"Styles...|[Intro: Pusha T]\\...|  8|           en|         en|      en|\n",
            "|         Family Ties|rap|  Cam'ron|2004| 41960|{\"Cam\\\\'ron\",\"Lad...|[Verse 1: Cam'ron...|  9|           en|         en|      en|\n",
            "|   Rockin and Rollin|rap|  Cam'ron|1998|  6399|       {\"Cam\\\\'ron\"}|[Verse 1]\\nAy yo ...| 10|           en|         en|      en|\n",
            "|       Lord You Know|rap|  Cam'ron|2004| 11882|{\"Cam\\\\'ron\",\"Jue...|[Chorus: Jaheim]\\...| 11|           en|         en|      en|\n",
            "|    Money On My Mind|rap|Lil Wayne|2005|128927|                  {}|[Intro]\\nYeah\\nMo...| 12|           en|         en|      en|\n",
            "|     Think Yall Know|rap| Fabolous|2003|  2530|                  {}|[Verse 1]\\nYou ai...| 13|           en|         en|      en|\n",
            "|              DEvils|rap|    JAY-Z|1996|504959|                  {}|[Produced by DJ P...| 14|           en|         en|      en|\n",
            "|        December 4th|rap|    JAY-Z|2003|283714|                  {}|[Produced by Just...| 15|           en|         en|      en|\n",
            "|        98 Freestyle|rap|    Big L|2000|297788|                  {}|[Verse 1]\\nYo, fu...| 16|           en|         en|      en|\n",
            "|What Happened to ...|rap|  Birdman|2002|100347|            {Clipse}|[Intro: Birdman]\\...| 17|           en|         en|      en|\n",
            "|Its Hot Some Like...|rap|    JAY-Z|1999|103549|                  {}|[Produced by Timb...| 18|           en|         en|      en|\n",
            "| Losing Weight Pt. 2|rap|  Cam'ron|2002| 32712|{\"Cam\\\\'ron\",\"Jue...|[Chorus: Cam'ron]...| 19|           en|         en|      en|\n",
            "|       Its Like That|rap|    JAY-Z|1998| 37692|       {\"Kid Capri\"}|[Intro: Jay-Z, Ki...|123|           en|         en|      en|\n",
            "|  More Gangsta Music|rap|  Cam'ron|2004| 20419|{\"Cam\\\\'ron\",\"Jue...|[Intro: Juelz San...|124|           en|         en|      en|\n",
            "+--------------------+---+---------+----+------+--------------------+--------------------+---+-------------+-----------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Read the CSV file into a DataFrame\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True, multiLine=True,\n",
        "                    quote=\"\\\"\", escape=\"\\\"\")\n",
        "\n",
        "# Show the first few rows of the DataFrame\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gp_TM96ZyPP1"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Define the condition for each column\n",
        "conditions = [col(column) != \"misc\" for column in df.columns]\n",
        "\n",
        "# Combine conditions using the AND operator\n",
        "final_condition = conditions[0]\n",
        "for condition in conditions[1:]:\n",
        "    final_condition = final_condition & condition\n",
        "\n",
        "# Apply the filter\n",
        "music = df.filter(final_condition)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRr8M0D208BN",
        "outputId": "69e4a936-434f-4881-ec23-6db578253648"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+---+------+----+-----+--------+------+---+-------------+-----------+--------+\n",
            "|title|tag|artist|year|views|features|lyrics| id|language_cld3|language_ft|language|\n",
            "+-----+---+------+----+-----+--------+------+---+-------------+-----------+--------+\n",
            "+-----+---+------+----+-----+--------+------+---+-------------+-----------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "music.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vZHCpzhJ4MQk"
      },
      "outputs": [],
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "music = music.withColumn('language_cld3', F.coalesce(music['language_cld3'], music['language_ft'], music['language']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xdCmvDIY5ksz"
      },
      "outputs": [],
      "source": [
        "music = music.drop('language_ft', 'language')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2Zu0SQKmD4EP"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Drop rows with missing values in 'tag' and 'language_cld3' columns\n",
        "music = music.na.drop(subset=['tag', 'language_cld3'])\n",
        "\n",
        "# Drop columns 'language_ft' and 'language'\n",
        "music = music.drop('language_ft', 'language')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbxYo8LWEzb-"
      },
      "outputs": [],
      "source": [
        "num_rows = music.count()\n",
        "num_cols = len(music.columns)\n",
        "\n",
        "print((num_rows, num_cols))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWLkMjDmGtN6"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, sum as spark_sum\n",
        "\n",
        "# Calculate the sum of null values for each column\n",
        "null_counts = music.agg(*[spark_sum(col(c).isNull().cast(\"int\")).alias(c) for c in music.columns])\n",
        "\n",
        "# Show the result\n",
        "null_counts.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08tb9OOr0xLB"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "# Define a UDF (User Defined Function) to count lines\n",
        "def count_lines(text):\n",
        "    return text.count(\"\\n\")\n",
        "\n",
        "# Register the UDF\n",
        "count_lines_udf = udf(count_lines, IntegerType())\n",
        "\n",
        "# Create a new column 'no_of_lines' using the UDF\n",
        "music = music.withColumn('no_of_lines', count_lines_udf(col('lyrics')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqoSGOKs2e62"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, regexp_replace\n",
        "\n",
        "# Replace newline characters with spaces in the 'lyrics' column\n",
        "music = music.withColumn('lyrics', regexp_replace(col('lyrics'), '\\n', ' '))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8gn77dk3EmL"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, regexp_replace\n",
        "\n",
        "# Define a PySpark UDF (User Defined Function) to remove text inside brackets\n",
        "def remove_text_inside_brackets_udf(input_string):\n",
        "    # Define a regular expression pattern for matching text inside square brackets\n",
        "    pattern = r'\\[.*?\\]'\n",
        "\n",
        "    # Use regexp_replace() function to replace the matched pattern with an empty string\n",
        "    result = re.sub(pattern, '', input_string)\n",
        "\n",
        "    return result\n",
        "\n",
        "# Register the UDF\n",
        "remove_text_udf = udf(remove_text_inside_brackets_udf)\n",
        "\n",
        "# Apply the UDF to the 'your_column' column and create a new column 'result'\n",
        "music = music.withColumn('result', remove_text_udf(col('your_column')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa2x10Kh3F3f"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, count\n",
        "\n",
        "# Calculate the count of each unique value in the 'tag' column\n",
        "tag_counts = music.groupBy('tag').agg(count('*').alias('count'))\n",
        "\n",
        "# Calculate the percentage for each tag\n",
        "tag_percentage = tag_counts.withColumn('percentage', (col('count') / music.count()) * 100)\n",
        "\n",
        "# Show the result\n",
        "tag_percentage.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41hAXndn3VgZ"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Define the conditions for filtering\n",
        "conditions = (col(\"tag\") == \"rap\") | (col(\"tag\") == \"pop\") | (col(\"tag\") == \"rock\")\n",
        "\n",
        "# Apply the filter\n",
        "subset = music.filter(conditions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWjnCbqF359g"
      },
      "outputs": [],
      "source": [
        "# Perform value counts on the 'artist' column\n",
        "artist_counts = subset.groupBy('artist').count()\n",
        "\n",
        "# Show the result\n",
        "artist_counts.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15sbkP544LUp"
      },
      "outputs": [],
      "source": [
        "# Filter out rows where 'artist' column contains 'genius' (case-insensitive)\n",
        "subset_filtered = subset.filter(~col(\"artist\").contains(\"genius\", caseInsensitive=True))\n",
        "subset_filtered.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7fSo0Ob4RUP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
